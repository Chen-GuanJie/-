#import "@preview/modern-sjtu-thesis:0.5.1": *

#let bf(x) = math.bold(math.upright(x))

== 界面不一致性检测 <app:screen>
在本工作中，我们首先训练一个计算机视觉模型，用于在设计原型界面和应用实现界面中识别预定义的组件类型。
对于检测到的组件，我们将其建模为一个可优化的组件对齐问题，并采用动态规划方法进行求解。

=== 组件检测 <app:widget-detection>

本节采用基于视觉的方法识别设计原型和实现界面中的组件。为获得高精度的控件检测能力，首先需构建大规模、高质量的训练数据集。

数据集构建方法如下：由于每张界面截图通常包含数十至上百个控件，人工逐一标注成本极高。为此，采用自动化标注流程，利用 uiautomator 工具控制手机自动遍历应用所有界面节点，采集每个界面的截图及其对应的 UI 层次信息。UI 层次信息中包含了控件的类型、名称、位置等详细属性，可据此自动生成每个控件在界面截图上的标注框。

然而，原始 UI 层次信息中往往混杂着大量布局容器（如 `LinearLayout`）、透明遮罩及装饰性节点，这些元素通常不具备实际的交互或视觉语义。为此，本文设计了一种基于包含关系与类型分类的启发式过滤算法，旨在精准提取具象化的 UI 组件。
具体而言，该算法首先对 UI 树进行深度优先遍历，分析节点间的父子包含关系，剔除那些由于嵌套而产生的冗余背景容器；其次，建立组件类型白名单，根据 Android View 的类名属性进行分类筛选，过滤掉单纯负责布局的结构化节点（如 `FrameLayout`、`RelativeLayout` 等），仅保留按钮（Button）、文本框（EditText）、图片（ImageView）等具有明确视觉特征和交互功能的实体控件。
自动化标注完成后，再辅以少量人工校验，对边界模糊或识别错误的标注进行微调。这一“自动预标注 + 人工修正”的混合流程使人工标注工作量减少了约 90%，在保证数据质量的同时显著提升了数据集构建效率。

基于上述数据集，训练先进的目标检测模型（如 YOLOv8 @yolov8），可准确识别界面上的各类组件及其在 @sec:ps 节中定义的类型。该方法统一了原型与实现两侧的组件提取流程，具备良好的跨应用泛化能力。

对于包含文本的组件类型（如 TextButton、CombinedButton 和 TextView），进一步集成光学字符识别（OCR）模型提取其文本内容，以支持后续一致性检查。最终，每个界面被转换为一个组件集合，每个组件均包含其位置、形状和类型等信息，如 @sec:ps 节所述。

=== 组件对齐 <app:widget-matching>
我们将组件匹配问题建模为一个动态规划问题，其算法流程如@algo:widget-matching 所示。
算法的输入为来自设计原型和应用实现的两个组件集合，
输出为这两个集合之间的匹配组件对集合。
该算法主要包含以下三个关键步骤：


- *步骤 1：基于递归布局分解的组件偏序关系（@algo:widget-matching 的第 2-- 3 行）。*
  传统的基于坐标（$y$-then-$x$）的排序在处理复杂嵌套布局时容易丢失结构语义。为此，我们提出了一种基于递归投影切割（Recursive Projection Cut）的组件线性化算法。
  该算法 $cal(L)(W)$ 将无序的组件集合 $W$ 递归地分解为具有视觉逻辑的有序序列。
  首先，算法分别沿 $X$ 轴（垂直切分）和 $Y$ 轴（水平切分）计算组件的投影间隙，尝试将集合 $W$ 划分为潜在的子组群 $cal(G)_x$ 和 $cal(G)_y$。
  为了确定当前的布局流向（即是行布局还是列布局），我们计算切分后各子组内部边界对齐的标准差 $sigma$，并选择对齐度更高（标准差更小）的方向作为最优分割轴 $d^*$：
  $
    d^* = arg min_(d in {x, y}) ( sum_(g in cal(G)_d) sigma("align"(g)) )
  $
  基于最优轴 $d^*$，集合 $W$ 被分割为有序子数组 $g_1, g_2, dots, g_k$。最终的偏序序列通过递归连接子组生成：
  $
    cal(L)(W) = cases(
      (w) & "若" |W|=1,
      cal(L)(g_1) plus cal(L)(g_2) plus dots plus cal(L)(g_k) & "其他"
    )
  $
  其中 $plus$ 表示序列连接操作。该算法来源于 `relative_loc` 布局分析模块，能有效保持视觉上相邻或包含的组件在逻辑序列中的邻接性。

- *步骤 2：组件相似度计算（@algo:widget-matching 的第 4--7 行）。*
  为了将组件匹配转化为一个可优化的数值问题，我们需要对两个组件集合中的每一对候选组件计算精细的相似度得分。该相似度度量采用多模态、分项归一化的策略，以增强对检测噪声及布局差异的鲁棒性。

  具体的分项指标如下：
  （i）位置相似度：基于组件边界框的中心位置及尺寸计算。既可采用坐标差的 L1 范数距离，也可并行计算边界框的交并比（IoU）作为位置重叠度的补充指标。为消除尺度依赖，位置得分被归一化至 $[0,1]$ 区间，其形式通常为：
  $"sim"_("pos") = min(1 / (alpha(|x_i-x_j|+|y_i-y_j|) + |w_i-w_j| + |h_i-h_j|)), 1)$
  或者使用 $"sim"_("pos")^("IoU") = "IoU"(b_i, b_j)$。在实践中，结合两者能显著提高对位置偏移与重叠变化的鲁棒性。

  （ii）面积相似度：衡量两个组件在像素面积上的相对差异，定义为
  $ "sim"_("area") = min(w_i h_i, w_j h_j) / max(w_i h_i, w_j h_j) $
  其值域为 $(0,1]$，越接近 1 表明两者面积越吻合。

  （iii）形状相似度：评估组件宽高比的一致性，用于区分长条形控件与方形控件，计算公式为：
  $ "sim"_("shape") = min(w_i/h_i, w_j/h_j) / max(w_i/h_i, w_j/h_j) $

  （iv）类型/语义相似度：基于检测到的控件类别标签赋值。若类别相同则 $"sim"_("type")=1$；若类别不同则赋予衰减因子 $delta in (0,1)$。

  对于包含文本的控件（如 TextView、TextButton、CombinedButton、InputBox），我们会利用 OCR 预先提取文本内容，并计算归一化的编辑距离或基于语义嵌入的余弦相似度，得到 $"sim"_("text") in [0,1]$。该项可与类型相似度结合，进一步增强语义判定的准确性。对于图标或图像类控件（如 IconButton、ImageView），则可引入颜色直方图、局部特征描述符或轻量级图像嵌入来计算视觉相似度 $"sim"_("visual")$，以弥补纯几个度量的不足。

  最终的相似度矩阵元素 $A_(i,j)$ 通常由各分项指标的加权几何平均得出：
  $
    A_(i,j) = "sim"_("pos")^(w_p) dot "sim"_("area")^(w_a) dot "sim"_("shape")^(w_s) dot "sim"_("type")^(w_t) dot "sim"_("text")^(w_("txt")) dot "sim"_("visual")^(w_("vis"))
  $
  其中权重 $w_k$ 可通过交叉验证或在小规模标注数据集上进行调优。计算完成后，会对 $A_(i,j)$ 执行阈值过滤（即若 $A_(i,j) < tau$ 则视为无效匹配），以降低错误匹配的概率。同时，对于面积过小的噪声框或非可视节点，应在预处理阶段予以剔除。

  上述设计在保证模型表达力的同时，兼顾了对检测误差、样式差异以及局部视觉变化的鲁棒性。

- *步骤 3：基于 LCS 的匹配（@algo:widget-matching 的第 8--20 行）。*
  在对组件及其布局进行序列化后，匹配问题可被表述为求解带权重的最长公共子序列（LCS），或等价转化为带有间隙惩罚（Gap Penalty）的序列对齐问题。与经典的二元匹配不同，本方法将相似度矩阵 $A$ 作为对角线匹配的增益项，并允许插入/删除（Gap）操作，从而有效处理多余或缺失的组件。

  动态规划的递推公式可表示为最大化累计得分的问题，并引入间隙惩罚 $g$：
  $ M_(i,j) = max(M_(i-1,j)-g, M_(i,j-1)-g, M_(i-1,j-1) + A_(i,j)) $
  其中 $M_(i,j)$ 表示考虑第一个集合前 $i$ 个组件与第二个集合前 $j$ 个组件时的最优累计匹配得分。间隙惩罚 $g$ 是一个关键超参数，控制模型对以非匹配（插入或删除）方式处理组件的容忍度：$g$ 值越大，模型越倾向于寻找一一对应的匹配；$g$ 值越小，则容忍更多的缺失或多余组件。

  为提升算法的计算效率与精度，通常在匹配前对相似度矩阵进行预剪枝（Pruning）：例如剔除 $A_(i,j)<tau$ 的低置信度候选对，或者仅保留每行/列中得分最高的 $k$ 个候选，从而显著降低动态规划的时间与空间复杂度。虽然标准的动态规划回溯即可恢复最佳匹配对，但在处理极长序列或高噪声数据时，也可采用束搜索（Beam Search）或 Hirschberg 算法来优化内存占用。

  匹配过程结束后，还需进行后处理以确保结果的一致性与可解释性：
  - 单调性与一对一约束：若回溯路径中出现一对多的情况，根据相似度得分与空间邻近性选择最优的一对一映射。
  - 空间验证：对每个匹配对再次验证其位置与尺寸的合理性（如中心距或 IoU 是否满足约束），剔除明显的误匹配。
  - 聚合策略：针对同一视觉元素被错误检测为多个碎片的情况，采用聚合策略（Merge）合并碎片后再重新计算相似度并匹配。

  这种基于 LCS 和序列对齐的方法，不仅保持了全局最优性，还具备处理局部缺失、顺序扰动及嵌套布局导致的序列差异的能力，从而能够在存在多余或缺失组件的复杂现实场景中，识别出稳健且可解释的组件对应关系。
#algox(
  label-name: "widget-matching",
  caption: [组件对齐算法],
  pseudocode-list(line-gap: 1em, indentation: 2em)[
    - #h(-1.5em) *input:* 设计稿组件集 $bf(W)_1 = {bf(w)_i | bf(w)_i = (x_i, y_i, w_i, h_i, t_i)}$，实现组件集 $bf(W)_2 = {bf(w)_j | bf(w)_j = (x_j, y_j, w_j, h_j, t_j)}$
    - #h(-1.5em) *output:* 匹配对 $bf(W)_1^m, bf(W)_2^m$
    + $bf(W)_1^m <- emptyset, bf(W)_2^m <- emptyset$
    + /* 步骤 1: 基于递归投影切割的组件线性化 */
    + $bf(W)_1 <- cal(L)(bf(W)_1)$
    + $bf(W)_2 <- cal(L)(bf(W)_2)$
    + /* 步骤 2: 计算相似度矩阵 */
    + 初始化相似度矩阵 $A <- bf(0)_(|bf(W)_1| times |bf(W)_2|)$
    + *for* $bf(w)_i in bf(W)_1, bf(w)_j in bf(W)_2$ *do*
      + $s i m_("pos") = min(1 / (alpha(|x_i - x_j| + |y_i - y_j|) + |w_i - w_j| + |h_i - h_j|), 1)$
      + $s i m_("area") = min(w_i h_i, w_j h_j) / max(w_i h_i, w_j h_j)$
      + $s i m_("shape") = min(w_i \/ h_i, w_j \/ h_j) / max(w_i \/ h_i, w_j \/ h_j)$
      + $s i m_("type") = bf(1)(t_i = t_j) + delta bf(1)(t_i != t_j)$
      + $A_(i,j) <- s i m_("pos") dot s i m_("area") dot s i m_("shape") dot s i m_("type")$
    + *end*
    + /* 步骤 3: 基于 LCS 的匹配 */
    + 初始化匹配矩阵 $M <- bf(0)_(|bf(W)_1|+1 times |bf(W)_2|+1)$
    + *for* $i = 1,dots,|bf(W)_1|, j = 1,dots,|bf(W)_2|$ *do*
      + $M_(i,j) <- max{M_(i,j-1), M_(i-1,j), M_(i-1,j-1) + A_(i-1,j-1)}$
    + *end*
    + /* 回溯匹配对 */
    + $i <- |bf(W)_1|, j <- |bf(W)_2|$
    + *while* $i > 0$ *and* $j > 0$ *do*
      + *if* $M_(i,j) = M_(i-1,j-1) + A_(i-1,j-1)$ *then*
        + $bf(W)_1^m <- bf(W)_1^m union {bf(w)_(i-1)}$
        + $bf(W)_2^m <- bf(W)_2^m union {bf(w)_(j-1)}$
        + $i <- i - 1, j <- j - 1$
      + *else* *if* $M_(i,j) = M_(i-1,j)$ *then*
        + $i <- i - 1$
      + *else*
        + $j <- j - 1$
      + *end*
    + *end*
    + *return* $bf(W)_1^m, bf(W)_2^m$
  ],
) <alg:widget-matching>

=== 不一致性报告生成 <app:screen-inconsistency-report>
基于组件匹配结果，我们可以识别出界面实现中的不一致性问题，如 @sec:ps 所定义。
我们考虑三类违规情况：多余组件、缺失组件以及语义变化。
前两类，即多余组件和缺失组件，
// 通过将匹配后的组件集合 $widgetset_1^{m}$ 和 $widgetset_2^{m}$
// 与初始组件集合 $\widgetset_1$ 和 $\widgetset_2$ 进行比较来识别。
最后一类，即语义变化，则在已匹配的组件对上进行判断。
若匹配的组件对属于不同的组件类型，则视为发生了语义变化。
对于组件类型相同的匹配对，
我们遵循 GVT @moran2018automated 的实践来判断组件是否发生变化：

+ 对于基于文本的组件（TextView、TextButton、InputBox 和 CombinedButton），其文本值序列的相似度比值需要高于阈值 $epsilon_(e d)$。
+ 对于基于图标的组件（IconButton、ImageView、InputBox 和 CombinedButton），二值颜色空间差异需低于阈值 $epsilon_(b i n a r y)$，同时出现频率最高的前 $k$ 种颜色的 RGB 差异也需小于阈值 $epsilon_(c o l o r)$。


最后，我们对组件类型 ``Chart`` 放宽比较条件，
即只要两个图表组件在界面中完成对齐，便认为其未发生变化。
这是因为设计原型中的图表往往仅作为示例，
其具体内容在实际实现中是可以动态变化的。



