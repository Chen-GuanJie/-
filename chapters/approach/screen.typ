#import "@preview/modern-sjtu-thesis:0.5.1": *
#import "../../define.typ": *

== 界面不一致性检测 <app:screen>
在本工作中，首先训练一个计算机视觉模型，用于在设计原型界面和应用实现界面中识别预定义的控件类型。
再将检测到的控件建模为一个可优化的控件对齐问题，并采用动态规划方法进行求解。

=== 控件检测 <app:widget-detection>

本节采用基于视觉的方法识别设计稿和实现界面中的控件。为获得高精度的控件检测能力，首先需构建大规模、高质量的训练数据集。

数据集构建方法如下：由于每张界面截图通常包含数十至上百个控件，人工逐一标注成本极高。为此，采用自动化标注流程，利用 uiautomator2 @uiautomator2 工具控制手机自动遍历应用所有界面节点，采集每个界面的截图及其对应的 UI 层次信息。UI 层次信息中包含了控件的类型、名称、位置等详细属性，可据此自动生成每个控件在界面截图上的标注框。

然而，原始 UI 层次信息中往往混杂着大量布局容器（如 LinearLayout）、透明遮罩及装饰性节点，这些元素通常不具备实际的交互或视觉语义。为此，本文设计了一种基于包含关系与类型分类的启发式过滤算法，旨在精准提取具象化的 UI 控件。
具体而言，该算法首先对 UI 树进行深度优先遍历，分析节点间的父子包含关系，剔除那些由于嵌套而产生的冗余背景容器；其次，建立控件类型白名单，根据 Android View 的类名属性进行分类筛选，过滤掉单纯负责布局的结构化节点（如 FrameLayout、RelativeLayout 等），仅保留按钮（Button）、文本框（EditText）、图片（ImageView）等具有明确视觉特征和交互功能的实体控件。
自动化标注完成后，再辅以少量人工校验，对边界模糊或识别错误的标注进行微调。这一“自动预标注 + 人工修正”的混合流程使人工标注工作量减少了约90%，在保证数据质量的同时显著提升了数据集构建效率。

基于上述数据集，训练先进的目标检测模型（如 YOLOv8 @yolov8），可准确识别界面上的各类控件及其在 @sec:ps 节中定义的类型。该方法统一了设计稿与实现两侧的控件提取流程，具备良好的跨应用泛化能力。

对于包含文本的控件类型（如 TextButton、CombinedButton 和 TextView），进一步集成光学字符识别（OCR）模型提取其文本内容，以支持后续一致性检查。最终，每个界面被转换为一个控件集合，每个控件均包含其位置、形状和类型等信息，如 @sec:ps 节所述。

=== 控件对齐 <app:widget-matching>
将控件匹配问题建模为一个动态规划问题，其算法流程如@algo:widget-matching 所示。
算法的输入为来自设计稿和应用实现的两个控件集合，
输出为这两个集合之间的匹配控件对集合。
该算法主要包含以下三个关键步骤：


- *步骤 1：基于递归布局分解的控件偏序关系（@algo:widget-matching 的第 2-- 3 行）。*
传统的基于坐标（$y$-then-$x$）的排序在处理复杂嵌套布局时容易丢失结构语义。为此，本文提出了一种基于递归投影切割（Recursive Projection Cut）的控件线性化算法。
该算法 $cal(L)(widgetset)$ 将无序的控件集合 $widgetset$ 递归地分解为具有视觉逻辑的有序序列。

首先，算法分别沿 $X$ 轴（垂直切分）和 $Y$ 轴（水平切分）计算控件的投影间隙，尝试将集合 $widgetset$ 划分为潜在的子组群 $cal(G)_x$ 和 $cal(G)_y$。
为了确定当前的布局流向（即是行布局还是列布局），计算切分后各子组内部边界对齐的标准差 $sigma$，并选择对齐度更高（标准差更小）的方向作为最优分割轴 $d^*$：
$
  d^* = arg min_(d in {x, y}) ( sum_(g in cal(G)_d) sigma("align"(g)) )
$
基于最优轴 $d^*$，集合 $widgetset$ 被分割为有序子数组 $g_1, g_2, dots, g_k$。最终的偏序序列通过递归连接子组生成：
$
  cal(L)(widgetset) = cases(
    (widget) & "若" |widgetset|=1,
    cal(L)(g_1) plus cal(L)(g_2) plus dots plus cal(L)(g_k) & "其他"
  )
$
其中 $plus$ 表示序列连接操作。该算法能有效保持视觉上相邻或包含的控件在逻辑序列中的邻接性。
// todo画个图

- *步骤 2：控件相似度计算（@algo:widget-matching 的第 4--7 行）。*
为了将控件匹配转化为一个可优化的数值问题，需要对两个控件集合中的每一对候选控件计算精细的相似度得分。该相似度度量采用多模态、分项归一化的策略，以增强对检测噪声及布局差异的鲁棒性。

具体的分项指标如下：
（i）位置相似度：基于控件边界框的中心位置及尺寸计算。既可采用坐标差的 L1 范数距离，也可并行计算边界框的交并比（IoU）作为位置重叠度的补充指标。为消除尺度依赖，位置得分被归一化至 $[0,1]$ 区间，其形式通常为：
$s i m_(p o s) = min(1 / (alpha(|x_i-x_j|+|y_i-y_j|) + |w_i-w_j| + |h_i-h_j|)), 1)$
或者使用 $s i m_(p o s)^(I o U) = "IoU"(b_i, b_j)$。在实践中，结合两者能显著提高对位置偏移与重叠变化的鲁棒性。

（ii）面积相似度：衡量两个控件在像素面积上的相对差异，定义为
$ s i m_(a r e a) = min(w_i h_i, w_j h_j) / max(w_i h_i, w_j h_j) $
其值域为 $(0,1]$，越接近 1 表明两者面积越吻合。

（iii）形状相似度：评估控件宽高比的一致性，用于区分长条形控件与方形控件，计算公式为：
$ s i m_(s h a p e) = min(w_i/h_i, w_j/h_j) / max(w_i/h_i, w_j/h_j) $

（iv）类型/语义相似度：基于检测到的控件类别标签赋值。若类别相同则 $s i m_(t y p e)=1$；若类别不同则赋予衰减因子 $delta in (0,1)$。

对于包含文本的控件（如 TextView、TextButton、CombinedButton、InputBox），会利用 OCR 预先提取文本内容，并计算归一化的编辑距离或基于语义嵌入的余弦相似度，得到 $s i m_(t e x t) in [0,1]$。该项可与类型相似度结合，进一步增强语义判定的准确性。对于图标或图像类控件（如 IconButton、ImageView），则可引入颜色直方图、局部特征描述符或轻量级图像嵌入来计算视觉相似度 $s i m_(v i s u a l)$，以弥补纯几个度量的不足。

最终的相似度矩阵元素 $A_(i,j)$ 通常由各分项指标的加权几何平均得出：
$
  A_(i,j) = s i m_(p o s)^(w_p) dot s i m_(a r e a)^(w_a) dot s i m_(s h a p e)^(w_s) dot s i m_(t y p e)^(w_t) dot s i m_(t e x t)^(w_(t x t)) dot s i m_(v i s u a l)^(w_(v i s))
$
其中权重 $w_k$ 可通过交叉验证或在小规模标注数据集上进行调优。计算完成后，会对 $A_(i,j)$ 执行阈值过滤（即若 $A_(i,j) < tau$ 则视为无效匹配），以降低错误匹配的概率。同时，对于面积过小的噪声框或非可视节点，应在预处理阶段予以剔除。

上述设计在保证模型表达力的同时，兼顾了对检测误差、样式差异以及局部视觉变化的鲁棒性。

- *步骤 3：基于 LCS 的匹配（@algo:widget-matching 的第 8--20 行）。*
在对控件及其布局进行序列化后，匹配问题可被表述为求解带权重的最长公共子序列（LCS），或等价转化为带有间隙惩罚（Gap Penalty）的序列对齐问题。与经典的二元匹配不同，本方法将相似度矩阵 $A$ 作为对角线匹配的增益项，并允许插入/删除（Gap）操作，从而有效处理多余或缺失的控件。

动态规划的递推公式可表示为最大化累计得分的问题，并引入间隙惩罚 $g$：
$ M_(i,j) = max(M_(i-1,j)-g, M_(i,j-1)-g, M_(i-1,j-1) + A_(i,j)) $
其中 $M_(i,j)$ 表示考虑第一个集合前 $i$ 个控件与第二个集合前 $j$ 个控件时的最优累计匹配得分。间隙惩罚 $g$ 是一个关键超参数，控制模型对以非匹配（插入或删除）方式处理控件的容忍度：$g$ 值越大，模型越倾向于寻找一一对应的匹配；$g$ 值越小，则容忍更多的缺失或多余控件。

为提升算法的计算效率与精度，通常在匹配前对相似度矩阵进行预剪枝（Pruning）：例如剔除 $A_(i,j)<tau$ 的低置信度候选对，或者仅保留每行/列中得分最高的 $k$ 个候选，从而显著降低动态规划的时间与空间复杂度。虽然标准的动态规划回溯即可恢复最佳匹配对，但在处理极长序列或高噪声数据时，也可采用束搜索（Beam Search）或 Hirschberg 算法来优化内存占用。

匹配过程结束后，还需进行后处理以确保结果的一致性与可解释性：
- 单调性与一对一约束：若回溯路径中出现一对多的情况，根据相似度得分与空间邻近性选择最优的一对一映射。
- 空间验证：对每个匹配对再次验证其位置与尺寸的合理性（如中心距或 IoU 是否满足约束），剔除明显的误匹配。
- 聚合策略：针对同一视觉元素被错误检测为多个碎片的情况，采用聚合策略（Merge）合并碎片后再重新计算相似度并匹配。

这种基于 LCS 和序列对齐的方法，不仅保持了全局最优性，还具备处理局部缺失、顺序扰动及嵌套布局导致的序列差异的能力，从而能够在存在多余或缺失控件的复杂现实场景中，识别出稳健且可解释的控件对应关系。
#algox(
  label-name: "widget-matching",
  caption: [控件对齐算法],
  pseudocode-list(line-gap: 1.6em, indentation: 2em)[
    - #h(-1.5em) *input:* 设计稿控件集 $widgetset_1 = {widgetset_i | widgetset_i = (x_i, y_i, w_i, h_i, t_i)}$，实现控件集 $widgetset_2 = {widgetset_j | widgetset_j = (x_j, y_j, w_j, h_j, t_j)}$
    - #h(-1.5em) *output:* 匹配对 $widgetset_1^m, widgetset_2^m$
    + $widgetset_1^m <- emptyset, widgetset_2^m <- emptyset$
    + /* 步骤 1: 基于递归投影切割的控件线性化 */
    + $widgetset_1 <- cal(L)(widgetset_1)$
    + $widgetset_2 <- cal(L)(widgetset_2)$
    + /* 步骤 2: 计算相似度矩阵 */
    + 初始化相似度矩阵 $A <- bf(0)_(|widgetset_1| times |widgetset_2|)$
    + *for* $widgetset_i in widgetset_1, widgetset_j in widgetset_2$ *do*
      + $s i m_(p o s) = min(1 / (alpha(|x_i - x_j| + |y_i - y_j|) + |w_i - w_j| + |h_i - h_j|), 1)$
      + $s i m_(a r e a) = min(w_i h_i, w_j h_j) / max(w_i h_i, w_j h_j)$
      + $s i m_(s h a p e) = min(w_i \/ h_i, w_j \/ h_j) / max(w_i \/ h_i, w_j \/ h_j)$
      + $s i m_(t y p e) = bf(1)(t_i = t_j) + delta bf(1)(t_i != t_j)$
      + $A_(i,j) <- s i m_(p o s) dot s i m_(a r e a) dot s i m_(s h a p e) dot s i m_(t y p e)$
    + *end*
    + /* 步骤 3: 基于 LCS 的匹配 */
    + 初始化匹配矩阵 $M <- bf(0)_(|widgetset_1|+1 times |widgetset_2|+1)$
    + *for* $i = 1,dots,|widgetset_1|, j = 1,dots,|widgetset_2|$ *do*
      + $M_(i,j) <- max{M_(i,j-1), M_(i-1,j), M_(i-1,j-1) + A_(i-1,j-1)}$
    + *end*
    + /* 回溯匹配对 */
    + $i <- |widgetset_1|, j <- |widgetset_2|$
    + *while* $i > 0$ *and* $j > 0$ *do*
      + *if* $M_(i,j) = M_(i-1,j-1) + A_(i-1,j-1)$ *then*
        + $widgetset_1^m <- widgetset_1^m union {widgetset_(i-1)}$
        + $widgetset_2^m <- widgetset_2^m union {widgetset_(j-1)}$
        + $i <- i - 1, j <- j - 1$
      + *else* *if* $M_(i,j) = M_(i-1,j)$ *then*
        + $i <- i - 1$
      + *else*
        + $j <- j - 1$
      + *end*
    + *end*
    + *return* $widgetset_1^m, widgetset_2^m$
  ],
) <alg:widget-matching>

=== 不一致性报告生成 <app:screen-inconsistency-report>
完成控件匹配后，本工作进一步对匹配结果进行分析与验证，以识别界面实现中与设计稿之间存在的各类不一致性问题，这些问题的定义详见 @sec:ps 章节。

根据控件的匹配状态与特征，系统可识别出三类主要的不一致性现象：

*第一类：多余控件（Extraneous Components）。* 这类控件出现在应用实现中但在设计稿中不存在，或者是匹配过程中未能找到对应的设计稿控件。多余控件通常表示应用实现中添加了设计未曾指定的功能或UI元素，可能是因为工程实现中出现了额外的业务逻辑或调试信息。

*第二类：缺失控件（Missing Components）。* 这类控件在设计稿中被明确指定但在应用实现中不存在或无法识别，表明实现未能完整遵循设计规范。识别缺失控件有助于发现实现中可能遗漏的功能或交互元素。

*第三类：语义变化（Semantic Variation）。* 这类控件虽然在两个界面版本中都存在并成功匹配，但在类型、内容或视觉表现上产生了变化。

前两类不一致性的识别方法较为直接，即通过将匹配后的控件集合 $widgetset_1^m$ 和 $widgetset_2^m$（从设计稿和应用实现中分别获得）
与初始检测到的完整控件集合 $widgetset_1$ 和 $widgetset_2$ 进行交集运算与差集分析。未在匹配集合中出现的控件，则分别归类为多余或缺失。

对于第三类语义变化的判断，需在已经成功匹配的控件对上执行更深层的语义检验。判断规则如下：

*类型级不一致：* 若某个匹配对中两个控件的类别标签不相同（例如设计稿中为 TextButton 而实现中为 TextView），则直接判定为发生了类型级的语义变化，属于严重的设计偏离。

*内容级不一致：* 对于类别相同的匹配对，需根据控件的具体类型进一步检验其内容与视觉表现。本工作参考了 GVT @moran2018automated 方法的做法，对不同类型的控件采用分化的判断策略：

+ 基于文本的控件（TextButton、TextView、InputBox、CombinedButton 等）：需对两个版本中的文本内容进行相似度计算。具体方法为：首先通过 OCR 或从 UI 树中提取文本信息，然后计算基于编辑距离（如莱文斯坦距离）或字符级序列相似度的得分，记为 $s i m_(t e x t)$。若 $s i m_(t e x t)$ 超过预设阈值 $epsilon_(e d)$，则认为文本内容基本保持一致；否则视为发生了内容变化。

+ 基于图标或图像的控件（IconButton、ImageView、InputBox、CombinedButton 等）：需对两个版本的视觉内容进行颜色与特征匹配。判断流程包括：（i）提取主色调，计算二值（黑白）颜色空间上的差异，需满足 $d i f f_(b i n a r y) < epsilon_(b i n a r y)$；（ii）提取出现频率最高的前 $k$ 种主要颜色，计算其 RGB 向量间的欧氏距离或余弦距离，需满足 $d i f f_(c o l o r) < epsilon_(c o l o r)$。两个条件均满足才认为图标保持视觉一致。

*特殊情形：图表控件（Chart）。* 对于图表类控件，鉴于其内容往往具有高度的动态性与数据驱动特性，设计稿中的图表通常仅作为布局占位符或样式参考，而非精确的数据表示。因此，对图表控件采用更为宽松的比较策略：只要设计稿和实现版本中的图表控件能够成功对齐（即在位置与尺寸上满足相似度阈值），便认为其在设计规范上保持一致，不对数据内容或具体数值进行逐一比对。

通过上述系统化的三级检验流程（多余/缺失检测 → 类型一致性检验 → 内容相似度检验），最终可生成一份详尽的不一致性报告，列举所有发现的偏离点及其严重程度，为后续的设计实现审查与改进工作提供量化依据。



